# PatchHybrid
By [Priya Naphade](https://github.com/pnaphade) and [Sean Wang](https://github.com/see-ann)

Adversarial patches are stickers which can be applied to images to induce misclassification in convolutional neural networks. We are attempting to use strategies from [PatchGuard](https://github.com/inspire-group/PatchGuard) and [PatchCleanser](https://github.com/inspire-group/PatchCleanser) to craft a more generalized defense against patch attacks. This code was originally taken from PatchGuard and we have modified it to investigate our ideas.
